{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82be9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a02e42d",
   "metadata": {},
   "source": [
    "# Assignment 1: DataFrame Basics\n",
    "\n",
    "Hi there!\n",
    "\n",
    "Can you read in the transactions dataset and report on:\n",
    "\n",
    "* The number of rows and columns\n",
    "* The names of the columns\n",
    "* The datatypes of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb37c0d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../retail/transactions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m path = \u001b[33m\"\u001b[39m\u001b[33m../retail/transactions.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# read in trasactions csv and create DataFrame\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m transactions = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# return DataFrame (df)\u001b[39;00m\n\u001b[32m      8\u001b[39m transactions\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ROG strix\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ROG strix\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ROG strix\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ROG strix\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ROG strix\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../retail/transactions.csv'"
     ]
    }
   ],
   "source": [
    "# A common practice is to create a path variable to pass to read_csv\n",
    "path = \"../retail/transactions.csv\"\n",
    "\n",
    "# read in trasactions csv and create DataFrame\n",
    "transactions = pd.read_csv(path)\n",
    "\n",
    "# return DataFrame (df)\n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of df: 84388 rows, 3 columns (not including index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5626e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of df: 84388 rows. Add 1 to max default index value to get row count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096d9dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtypes attribute returns column names and their data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68959027",
   "metadata": {},
   "source": [
    "# Assignment 2: Exploring DataFrames\n",
    "\n",
    "Hello!\n",
    "\n",
    "* Can you quickly inspect the first 5 rows of the transactions data? \n",
    "\n",
    "* Then, dive a bit more deeply into the data and check if there are any missing values.\n",
    "* What about the number of unique dates? I want to make sure we didn’t leave any out.\n",
    "* Finally, can you report the mean, median, min and max of “transactions”?  I want to check for any anomalies in our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe682d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at top 5 rows with .head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8447e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .isna().sum() on df to get missing counts for all columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6c24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use info to determine missing counts - none are missing!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use describe to return the specified aggregations (and more!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33210d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 for unique dates - once you know how to access columns :D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bac1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2 for unique dates - speecify include=\"all\" to get stats on text columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e6a1ad",
   "metadata": {},
   "source": [
    "# Exercise 3 - Accessing DataFrames\n",
    "\n",
    "Hi, starting to dive deeper into this data.\n",
    "\n",
    "I noticed that the first row is the only one from 2013-01-01.\n",
    "\n",
    "* Can you get me a copy of the DataFrame that excludes that row, and only includes “store_nbr” and “transactions”?\n",
    "* Also, can you report the number of unique store numbers?\n",
    "* Finally, return the total number of transactions in millions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fca9359",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e53911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip the first row via slicing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sum of store number column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce57d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide sum of transactions by millions to get in units of millions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef5b93",
   "metadata": {},
   "source": [
    "# Assignment 4: Dropping Data and Duplicates\n",
    "\n",
    "Hi there!\n",
    "\n",
    "Can you:\n",
    "\n",
    "1. Drop the first row of data? We want it permanently removed. \n",
    "2. Drop the date column but not in place\n",
    "3. Return a dataframe that only includes the last row for each of the stores.\n",
    "\n",
    "Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19dd02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the first row of data in place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78560e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop date but not in place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2398f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate rows subsetting by store number. keep last entry for each store\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31b812d",
   "metadata": {},
   "source": [
    "# Assignment 5: Missing Data\n",
    "\n",
    "Hello, \n",
    "\n",
    "Can you tell if any dates or prices are missing in the oil dataset?\n",
    "\n",
    "Then compare the mean of the oil series when filling in with mean vs. filling in with 0.\n",
    "\n",
    "Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab747f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oil = pd.read_csv(\"../retail/oil.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3543f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info can be used to infer missing counts 1218 - 1175 = 43\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But usually easier to use isna().sum() - let the computer count for you :D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf390b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean of oil series after filling missing values with 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faadf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean of oil series after filling missing values with the mean of oil price\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e8103",
   "metadata": {},
   "source": [
    "# Assignment 6: Filtering DataFrames\n",
    "\n",
    "I need some quick research on store 25:\n",
    "\n",
    "* First, calculate the percentage of times ALL stores had more than 2000 transactions\n",
    "* Then, calculate the percentage of times store 25 had more than 2000 transactions, and calculate the sum of transactions on these days\n",
    "* Finally, sum the transactions for stores 25 and 3, that occurred in May or June, and had less than 2000 transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all stores > 2500 percentage occurence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times store 25 had > 2000 divided by total days for store 25 to get percent of time it happened\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98eb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of transactions where store 25 had > 2000 transactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc729c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of transactions for stores 25 and 31 in months May and June on days they had less than 2000 transactions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4dbc56",
   "metadata": {},
   "source": [
    "# Assignment 7: Sorting DataFrames\n",
    "\n",
    "Hi there,\n",
    "* Can you get me a dataset that includes the 5 days with the highest transactions counts? Any similarities between them?\n",
    "* Then, can you get me a dataset sorted by date from earliest to most recent, but with the highest transactions first and the lowest transactions last for each day?\n",
    "* Finally, sort the columns in reverse alphabetical order. \n",
    "\n",
    "Thanks!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ba590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe by values in transaction column in descending order (ascending = False)\n",
    "# then grab first 5 rows to retrieve 5 highest days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a91820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by date in ascending order, and trasactions in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort columns in reverse alphabetical order using sort_index on the column axis (1), in descending order\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18621b8",
   "metadata": {},
   "source": [
    "# Assignment 8: Modifying Columns\n",
    "\n",
    "Just some quick work, but can you send me the transaction data with the columns renamed?\n",
    "\n",
    "* Rename `transactions` to `transaction_count` and `store_nbr` to `store_number`.\n",
    "* Reorder the columns so date is first, then store number, then transaction count.\n",
    "\n",
    "Thanks!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d1bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use rename to change column names\n",
    "# Use reindex, axis=1, to reorder columns (this can also be done by assignment FYI)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca66fb2",
   "metadata": {},
   "source": [
    "# Assignment 9: Column Creation\n",
    "\n",
    "Just some quick work, but can you send me the transaction data with the columns renamed?\n",
    "\n",
    "* Create a `pct_to_target` column that divides transactions by 2500.\n",
    "* Then, create a `met_target` column that returns True if `pct_to_target` is greater than or equal to 1.\n",
    "* Next, create a `bonus_payable` column that equals 100 if `met_target` is True, and 0 if not. Then sum the bonus payable column.\n",
    "* Finally, create columns for month and day of week as integers. There is some helper code for these dateparts below.\n",
    "\n",
    "\n",
    "\n",
    "Thanks!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target based columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e861ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call sum on \"bonus_payable\" column to get total sum of bonus paid\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0068fd8",
   "metadata": {},
   "source": [
    "# Assignment 10: np.select\n",
    "\n",
    "Hi there! I need a few columns created.\n",
    "\n",
    "1. Create a ‘seasonal_bonus’ column that applies to these dates: \n",
    "    * All days in December (month = 12)\n",
    "    * Sundays (day_of_week = 6) in May (month = 5)\n",
    "    * Mondays (day_of_week = 0) in July (month = 7)\n",
    "2. Call the December bonus ‘Holiday Bonus’, the May bonus ‘Corporate Month’, and the July bonus ‘Summer Special’. If no bonus applies, the column should display ‘None’. \n",
    "3. Finally, calculate the total bonus owed at $100 per day.\n",
    "\n",
    "Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae4968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1349a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the three conditions\n",
    "\n",
    "\n",
    "# specify outcomes for each condition\n",
    "\n",
    "# Call the select method, passing in conditions, choices, and a default value of 'None' if no condition met\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at frequency for each \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e407cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use value counts to extract counts of each holiday, \n",
    "# slice the series returned by value counts, and sum relevant values before multiply by 100 to get bonus owed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21419bc2",
   "metadata": {},
   "source": [
    "# Assignment 11: Assign \n",
    "\n",
    "* Drop the columns that have been created so far (keep only date, store_number, and transaction count), and recreate them using the assign method.\n",
    "* Then sum the seasonal bonus owed once again to make sure the numbers are correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca47abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we created in prior exercises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create same columns with assign\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ccd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same method as assignment 10\n",
    "\n",
    "transactions.loc[:, \"seasonal_bonus\"].value_counts().iloc[1:].sum() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b60432",
   "metadata": {},
   "source": [
    "# Assignment 12: Memory Optimization\n",
    "\n",
    "Reduce the memory usage of the transactions DataFrame to below 5MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b389b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebefdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a520fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - you may have been more conservative here, and that's OK.\n",
    "# The main point is reducing memory consumption. Playing it safe is often wise.\n",
    "\n",
    "transactions = transactions.astype(\n",
    "    {\n",
    "        \"store_number\": \"Int8\",\n",
    "        \"transaction_count\": \"Int16\",\n",
    "        \"bonus_payable\": \"Int8\",\n",
    "        \"month\": \"Int8\",\n",
    "        \"day_of_week\": \"Int8\",\n",
    "        \"seasonal_bonus\": \"category\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cccb5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c1b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# down to 2.9MB vs. 10.1 to start. Will work on Chandler's grandparents computer!\n",
    "\n",
    "transactions.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bfc395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
